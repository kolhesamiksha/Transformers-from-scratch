{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe37f92a-8a5e-4afa-b62f-60a080e230ef",
   "metadata": {},
   "source": [
    "## Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb18e23-832b-48c1-95d5-8059d9addd81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660ad5dc-d83f-4cd1-8743-0e07a1557a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length = 4    # 4 words\n",
    "batch_size = 1\n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "x = torch.randn((batch_size, sequence_length, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2b5f15-23c3-433d-ab4e-be30ba1a43fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2694, -1.2359, -0.9782,  ..., -0.8081, -0.3821, -0.1259],\n",
       "         [-0.5397, -1.9118, -1.3352,  ..., -0.3518,  0.4289,  1.0851],\n",
       "         [ 1.7145,  0.7449,  0.7258,  ...,  1.4510, -1.5135,  1.3949],\n",
       "         [-1.0144,  0.3269, -0.1946,  ...,  0.6608, -0.5699, -0.6814]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f586d290-7914-44ff-948b-b16435e92834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim , 3 * d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a53abf-f5bb-4dea-abe1-fd0dc7ef8326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qkv = qkv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85232631-b511-409b-aaa4-56df2fcc8181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2081, -0.2032,  0.7234,  ..., -0.2698, -0.6272,  1.5717],\n",
       "         [-0.0928, -0.2201,  0.7269,  ..., -0.4078, -0.4672,  0.2020],\n",
       "         [-0.0757,  0.0749, -0.1767,  ..., -0.1290,  0.5579, -0.3411],\n",
       "         [ 0.3501, -0.2855, -0.2798,  ..., -0.4156,  0.3686, -0.0827]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b913395c-67d9-40b9-a6f6-0a7ab202aefd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7adc911-29ad-4124-b48d-648314224ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv.permute(0, 2, 1, 3) # [batch_size, num_heads, sequence_length, 3*head_dim]\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c1ab63c-4fa4-44fa-be71-55fd4afbb79d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3, dim=-1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed345d-f05e-4639-8b62-795ebe264909",
   "metadata": {},
   "source": [
    "## Self Attention for multiple heads\n",
    "\n",
    "For a single head:\n",
    "$$\n",
    "\\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{new V} = \\text{self attention}.V\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf2b87f-ce45-46c8-9021-11ca857c138c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fba5555e-14d9-4ed0-bd02-9426ab44cdd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9740\\3717780648.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3641.)\n",
      "  k.T.shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 8, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af446d7f-4ba8-4eea-957e-b9f3d5277b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2370, -0.6806],\n",
       "        [-1.1236,  0.9982],\n",
       "        [-0.0747,  0.1154]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(2, 3)\n",
    "torch.transpose(y, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "896e6229-f25b-497a-b2dc-d6d3c983d757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2370, -0.6806],\n",
       "        [-1.1236,  0.9982],\n",
       "        [-0.0747,  0.1154]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(y, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74ee7967-f49d-45b6-8edc-8d5041833093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.size() , float('-inf'))\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask[0][1] # mask for input to a single head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "709dd251-520c-4cf0-ba0d-df31d5e709a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0146,    -inf,    -inf,    -inf],\n",
       "          [ 0.1821,  0.4276,    -inf,    -inf],\n",
       "          [-0.2670, -0.0280, -0.3163,    -inf],\n",
       "          [ 0.1123, -0.3236,  0.1044,  0.0513]],\n",
       "\n",
       "         [[ 0.5942,    -inf,    -inf,    -inf],\n",
       "          [-0.0722, -0.2064,    -inf,    -inf],\n",
       "          [-0.7415, -0.0156, -0.2027,    -inf],\n",
       "          [ 0.1921, -0.1916,  0.0409, -0.0272]],\n",
       "\n",
       "         [[-0.4398,    -inf,    -inf,    -inf],\n",
       "          [-0.3835, -0.1010,    -inf,    -inf],\n",
       "          [ 0.1020, -0.0861, -0.0317,    -inf],\n",
       "          [-0.4299, -0.4382, -0.4538,  0.1704]],\n",
       "\n",
       "         [[-0.2862,    -inf,    -inf,    -inf],\n",
       "          [-0.0650, -0.4676,    -inf,    -inf],\n",
       "          [-0.2815, -0.2485,  0.1706,    -inf],\n",
       "          [ 0.0828, -0.0689, -0.1944, -0.4020]],\n",
       "\n",
       "         [[-0.3037,    -inf,    -inf,    -inf],\n",
       "          [-0.1706, -0.1514,    -inf,    -inf],\n",
       "          [-0.1198, -0.2822, -0.1319,    -inf],\n",
       "          [ 0.0145,  0.1137,  0.2772,  0.0864]],\n",
       "\n",
       "         [[-0.5260,    -inf,    -inf,    -inf],\n",
       "          [-0.0024,  0.2771,    -inf,    -inf],\n",
       "          [ 0.1400, -0.9896,  0.1953,    -inf],\n",
       "          [-0.4258, -0.4133, -0.1759,  0.2869]],\n",
       "\n",
       "         [[-0.0884,    -inf,    -inf,    -inf],\n",
       "          [ 0.1313, -0.0365,    -inf,    -inf],\n",
       "          [-0.0541, -0.3435,  0.0273,    -inf],\n",
       "          [ 0.3891,  0.0542,  0.0990,  0.2545]],\n",
       "\n",
       "         [[ 0.0798,    -inf,    -inf,    -inf],\n",
       "          [-0.2395, -0.4387,    -inf,    -inf],\n",
       "          [-0.3361,  0.0173,  0.2945,    -inf],\n",
       "          [ 0.5458,  0.4827,  0.0282, -0.1344]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled+mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfa61ed6-1af9-42ca-9b76-414cadfbdf47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bba9f0ce-c2f5-4fd3-a454-2066a737a55d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention, v)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac24da5-7254-4f86-80a7-0fa0493efbc3",
   "metadata": {},
   "source": [
    "## Encapsulate all in Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64f0a064-2f9a-413c-b056-cfcd3321c1cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58dcd2ba-f98b-49ce-89af-caa7083d5378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02c9e8f2-fe7a-4bce-aded-4e0833d873d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e437a8c5-947b-4900-b0bc-4347b29b790d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f61737b0-0d53-45f6-9163-87521e38ecbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = linear_layer(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5965a2fe-3573-4389-b648-1d806ca9d517",
   "metadata": {},
   "source": [
    "## All in One set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8c32f0b-16ba-4055-b02c-fefdcfa2c7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1dd67a09-be25-4ffd-8cdd-85afbcdf3bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
      "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336fdc9-81b6-4500-8da0-e7d6223f5fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
